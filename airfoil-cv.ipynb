{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef calculate_area(contours,image4):\n    # 获取轮廓点集\n    contour = contours[-1]\n\n    # 提取横坐标\n    x_coordinates = contour[:, 0, 0]\n\n    # 获取最左和最右坐标\n    leftmost_x = np.min(x_coordinates)\n    rightmost_x = np.max(x_coordinates)\n#     print(\"leftmost_x,rightmost_x:\",leftmost_x,rightmost_x)\n    image_crop=image4[:,:rightmost_x]\n    # 获取图像的高度和宽度\n    height, width = image4.shape[:2]\n#     print(\"height_crop, width_crop:\",height, width)\n    for i in range(len(contours)):\n        # 清空画布\n        plt.clf()\n        is_connected_to_boundary = False\n\n        for point in contours[i]:\n            x, y = point[0]\n\n            # 检查轮廓上的某个点是否与图像边界相连\n            if cv2.pointPolygonTest(contours[i], (x, y), True) <= 0:\n                is_connected_to_boundary = True\n                break\n        if cv2.isContourConvex(contours[i]) is not None and not is_connected_to_boundary:\n            print(True)\n        cv2.drawContours(image4, contours, i, (0, 0, 255), 20, 8)\n        # 创建一个新的图形\n        plt.figure()\n\n        # 将图像显示在图形中\n        plt.imshow(image4)\n\n        # 显示图形\n        plt.show()\n\n    \n    morph_find(image_crop)\n    # 将图像转换为HSV颜色空间\n    hsv = cv2.cvtColor(image_crop, cv2.COLOR_BGR2HSV)\n\n    # 定义深蓝色范围\n    lower_dark_blue = np.array([110, 50, 50])  # 深蓝色下限\n    upper_dark_blue = np.array([130, 255, 255])  # 深蓝色上限\n\n    # 创建深蓝色掩码\n    dark_blue_mask = cv2.inRange(hsv, lower_dark_blue, upper_dark_blue)\n\n    # 计算非零像素数量\n    blue_area = cv2.countNonZero(dark_blue_mask)\n#     print(blue_area)\n\n#     # 创建一个新的图形\n#     plt.figure()\n\n#     # 将图像显示在图形中\n#     plt.imshow(dark_blue_mask)\n\n#     # 显示图形\n#     plt.show()\n    return blue_area","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T12:54:44.669959Z","iopub.execute_input":"2023-09-01T12:54:44.670360Z","iopub.status.idle":"2023-09-01T12:54:44.689681Z","shell.execute_reply.started":"2023-09-01T12:54:44.670324Z","shell.execute_reply":"2023-09-01T12:54:44.688373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def capture_airfoil(file_path):\n    image = cv2.imread(file_path)\n    # 获取图像的高度和宽度\n    height, width = image.shape[:2]\n    print(\"height, width:\",height, width)\n\n    # 计算要保留的像素范围\n    top_h=int(0.15*height)\n    bottom_h=int(0.85*height)\n\n    top_w=int(0.15*width)\n    bottom_w=int(0.85*width)\n\n    # 截取图像的上部分\n    image = image[top_h:bottom_h, top_w:bottom_w]\n    height, width = image.shape[:2]\n    # 创建一个新的图形\n    plt.figure()\n\n    # 将图像显示在图形中\n    plt.imshow(image)\n\n    # 显示图形\n    plt.show()\n\n    # 将图像转换为灰度图像\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n    # 对灰度图像进行阈值处理\n    _, threshold = cv2.threshold(gray, 230, 255, cv2.THRESH_BINARY)\n    \n    # 连通组件分析\n    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(threshold)\n\n    # 获取每个区域掩膜的单独最大和最小纵坐标\n    for i in range(1, num_labels):  # 跳过背景区域（标签0）\n        min_y = stats[i, 1]\n        max_y = stats[i, 1] + stats[i, 3]\n        if(min_y>0 and max_y<height):\n            region_mask = np.uint8(labels == i) * 255  # 创建区域掩膜\n            region_image = cv2.bitwise_and(image, image, mask=region_mask)  # 通过按位与操作提取区域图像\n\n\n    # 使用Canny边缘检测\n    edges = cv2.Canny(region_image, 100, 200)\n\n    # 寻找最外侧的轮廓\n    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    return calculate_area(contours,image)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T12:54:44.669959Z","iopub.execute_input":"2023-09-01T12:54:44.670360Z","iopub.status.idle":"2023-09-01T12:54:44.689681Z","shell.execute_reply.started":"2023-09-01T12:54:44.670324Z","shell.execute_reply":"2023-09-01T12:54:44.688373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image4 = cv2.imread(\"/kaggle/input/flowfieldpic/Pic/case1-100.png\")\nimage4 = cv2.imread(\"/kaggle/input/flowfieldpic/Pic/case102-240.png\")\n\ncapture_airfoil(image4)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T11:19:46.527186Z","iopub.execute_input":"2023-09-05T11:19:46.527513Z","iopub.status.idle":"2023-09-05T11:19:46.909921Z","shell.execute_reply.started":"2023-09-05T11:19:46.527486Z","shell.execute_reply":"2023-09-05T11:19:46.908723Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image4 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/flowfieldpic/Pic/case1-100.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m image4 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/flowfieldpic/Pic/case102-240.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m capture_airfoil(image4)\n","\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"],"ename":"NameError","evalue":"name 'cv2' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import os\nimport glob\n\n# 指定文件夹路径\npic_path = glob.glob(\"/kaggle/input/flowfieldpic/Pic/*\")\n\ndf = pd.DataFrame(columns=[\"图片名\", '失速面积','失速开始位置'])\n\n# 遍历文件夹中的所有文件\nfor file_path in pic_path:\n    area=capture_airfoil(file_path)\n    # 迭代添加行数据\n    data = {'图片名': file_name,\n            '失速面积': area,\n           '失速开始位置':start_coor}\n    df.loc[len(df)] = data\n    # 保存到Excel文件\n    df.to_excel('分类结果.xlsx', index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-29T07:55:45.826591Z","iopub.execute_input":"2023-08-29T07:55:45.827144Z","iopub.status.idle":"2023-08-29T11:33:51.366279Z","shell.execute_reply.started":"2023-08-29T07:55:45.827099Z","shell.execute_reply":"2023-08-29T11:33:51.364340Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils, models\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MNIST_data(Dataset):\n    \"\"\"MNIST dtaa set\"\"\"\n    \n    def __init__(self, file_path, \n                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n                ):\n        \n        df = pd.read_csv(file_path)\n        \n        if len(df.columns) == 784:\n            # test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            # training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n            \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is not None:\n            return self.transform(self.X[idx]), self.y[idx]\n        else:\n            return self.transform(self.X[idx])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\nfrom PIL import Image\n\n# 定义训练集的转换\ntrain_transform = transforms.Compose([\n    transforms.Resize((580, 844)),\n    transforms.ToTensor(),  # 转换为张量\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 归一化\n])\n\n# 定义测试集的转换\ntest_transform = transforms.Compose([\n    transforms.Resize((580, 844)),\n    transforms.ToTensor(),  # 转换为张量\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 归一化\n])\n\n# 自定义数据集类\nclass MyDataset(Dataset):\n    def __init__(self, dataframe, test_size=0.2, random_state=42, transform=None):\n        self.samples = dataframe['图片名'].values\n        self.labels = dataframe['是否失速'].values\n\n        # 根据标签进行分层采样，保持正样本比例一致\n        self.train_samples, self.test_samples, self.train_labels, self.test_labels = train_test_split(\n            self.samples, self.labels, test_size=test_size, stratify=self.labels, random_state=random_state\n        )\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.train_samples)\n\n    def __getitem__(self, index):\n        sample_path = '/kaggle/input/flowfieldpic/Pic/' + self.train_samples[index]\n        sample = Image.open(sample_path)\n        label = self.train_labels[index]\n        if self.transform is not None:\n            sample = self.transform(sample)\n        # 在这里进行样本和标签的预处理，如果需要的话\n\n        return sample, label","metadata":{"execution":{"iopub.status.busy":"2023-08-31T08:40:52.228239Z","iopub.execute_input":"2023-08-31T08:40:52.228651Z","iopub.status.idle":"2023-08-31T08:40:52.240487Z","shell.execute_reply.started":"2023-08-31T08:40:52.228617Z","shell.execute_reply":"2023-08-31T08:40:52.239416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 读取包含文件名和属性值的DataFrame\ndf = pd.read_excel('/kaggle/input/classification-output/output.xlsx')\ndf_unique=df.drop_duplicates()\n# 划分训练集和测试集\n\ndf_unique['是否失速'] = df_unique['失速面积'].apply(lambda x: 1 if x > 5000 else 0)\n\ntrain_dataset = MyDataset(df_unique,transform=train_transform)\ntest_dataset = MyDataset(df_unique,transform=test_transform)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T08:41:15.975227Z","iopub.execute_input":"2023-08-31T08:41:15.975633Z","iopub.status.idle":"2023-08-31T08:41:16.571642Z","shell.execute_reply.started":"2023-08-31T08:41:15.975599Z","shell.execute_reply":"2023-08-31T08:41:16.570665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet18\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-08-31T06:35:21.913647Z","iopub.execute_input":"2023-08-31T06:35:21.914778Z","iopub.status.idle":"2023-08-31T06:35:21.923121Z","shell.execute_reply.started":"2023-08-31T06:35:21.914738Z","shell.execute_reply":"2023-08-31T06:35:21.921722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()  # 清理未使用的GPU内存\ntorch.cuda.reset_peak_memory_stats()  # 重置最大分配内存\n\nremaining_memory = torch.cuda.max_memory_allocated() - torch.cuda.memory_allocated()\nremaining_cache = torch.cuda.max_memory_reserved() - torch.cuda.memory_reserved()\n\nprint(f\"Remaining memory: {remaining_memory / (1024**2):.2f} MiB\")\nprint(f\"Remaining cache: {remaining_cache / (1024**2):.2f} MiB\")","metadata":{"execution":{"iopub.status.busy":"2023-08-31T06:35:21.926593Z","iopub.execute_input":"2023-08-31T06:35:21.928046Z","iopub.status.idle":"2023-08-31T06:35:21.994961Z","shell.execute_reply.started":"2023-08-31T06:35:21.927990Z","shell.execute_reply":"2023-08-31T06:35:21.993881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess as sp\nimport os\n\ndef get_gpu_memory():\n    _output_to_list = lambda x: x.decode('ascii').split('\\n')[:-1]\n\n    ACCEPTABLE_AVAILABLE_MEMORY = 1024\n    COMMAND = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n    memory_free_info = _output_to_list(sp.check_output(COMMAND.split()))[1:]\n    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n    return memory_free_values\nprint(get_gpu_memory())","metadata":{"execution":{"iopub.status.busy":"2023-08-31T06:35:21.996606Z","iopub.execute_input":"2023-08-31T06:35:21.997377Z","iopub.status.idle":"2023-08-31T06:35:22.020422Z","shell.execute_reply.started":"2023-08-31T06:35:21.997337Z","shell.execute_reply":"2023-08-31T06:35:22.019331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义分类器模型\nclass Classifier(nn.Module):\n    def __init__(self, num_classes):\n        super(Classifier, self).__init__()\n        self.resnet = resnet18(weights=True)\n        self.fc = nn.Linear(1000, num_classes)\n\n    def forward(self, x):\n        features = self.resnet(x)\n        output = self.fc(features)\n        return output\n\n# 设置超参数\nnum_classes = 2\nlr = 0.001\nbatch_size = 64\nnum_epochs = 100\n\n# 创建数据加载器\ntrain_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size, shuffle=False)\n\n# 创建模型并定义损失函数和优化器\nmodel = Classifier(num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)\n\n\n# 模型训练\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nprint(1)\nfor epoch in range(num_epochs):\n    model.train()\n    print(get_gpu_memory())\n    for images, labels in train_dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # 在测试集上评估模型性能\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_dataloader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    torch.save(model.state_dict(), f'model_epoch_{epoch}.pt')\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-31T08:47:08.423295Z","iopub.execute_input":"2023-08-31T08:47:08.423696Z","iopub.status.idle":"2023-08-31T11:49:29.483952Z","shell.execute_reply.started":"2023-08-31T08:47:08.423662Z","shell.execute_reply":"2023-08-31T11:49:29.482212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncheckpoint = torch.load('model_epoch_19.pt')\nmodel.load_state_dict(checkpoint)\n\nall_files = os.listdir('/kaggle/input/flowfieldpic/Pic')\n\nfiltered_files = [file for file in all_files if file not in df['图片名'].tolist()]\n# 模型训练\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n# 设置模型为评估模式\nmodel.eval()\n\ndf = pd.DataFrame(columns=[\"图片名\", '是否失速'])\n\n\n# 输入数据进行推理\nfor file in filtered_files:\n#     sample_path = '/kaggle/input/flowfieldpic/Pic/' + file\n    sample_path = '/kaggle/input/flowfieldpic/Pic/' + 'case78-235.png'\n    sample = Image.open(sample_path)\n    transform = transforms.ToTensor()\n    tensor_image = transform(sample)\n    sample = tensor_image.to(device)\n    # 增加一个维度\n    output = model(sample.unsqueeze(0))\n    _, predicted = torch.max(output.data, 1)\n    print(predicted.cpu().numpy())\n    data = {'图片名': file,\n            '是否失速': predicted.cpu().numpy()}\n    df.loc[len(df)] = data\n    # 保存到Excel文件\n    df.to_excel('classification_output.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:56:03.439442Z","iopub.execute_input":"2023-08-31T11:56:03.440663Z","iopub.status.idle":"2023-08-31T11:56:05.835662Z","shell.execute_reply.started":"2023-08-31T11:56:03.440609Z","shell.execute_reply":"2023-08-31T11:56:05.834069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport os\nfrom PIL import Image\n\n\nclass MyDataset(Dataset):\n    def __init__(self, root, train=True, transform=None):\n        super(MyDataset, self).__init__()\n        self.root = root\n        self.train = train\n        self.transform = transform\n        imgs = []\n\n        if train:\n            imgs = list(zip(os.listdir(root+'/train'), True*len(os.listdir(root+'/train'))))\n                \n        else:\n            imgs = list(zip(os.listdir(root+'/test'), False*len(os.listdir(root+'/test'))))\n\n        self.imgs = imgs\n\n    def __getitem__(self, index):\n        fn, label = self.imgs[index]\n        img = Image.open(self.root+fn).convert('RGB')    # 按路径读取图片\n\n        if self.transform is not None:\n            img = self.transform(img)    # 对图片进行 transform 操作\n        return img, label\n\n    def __len__(self):\n        return len(self.imgs)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T06:36:59.410845Z","iopub.status.idle":"2023-08-31T06:36:59.411673Z","shell.execute_reply.started":"2023-08-31T06:36:59.411411Z","shell.execute_reply":"2023-08-31T06:36:59.411436Z"},"trusted":true},"execution_count":null,"outputs":[]}]}